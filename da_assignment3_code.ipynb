{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_10_9_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import math\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_since_last_donation</th>\n",
       "      <th>total_number_of_donations</th>\n",
       "      <th>total_blood_donated</th>\n",
       "      <th>months_since_first_donation</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "      <td>748.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.506684</td>\n",
       "      <td>5.514706</td>\n",
       "      <td>1378.676471</td>\n",
       "      <td>34.282086</td>\n",
       "      <td>0.237968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.095396</td>\n",
       "      <td>5.839307</td>\n",
       "      <td>1459.826781</td>\n",
       "      <td>24.376714</td>\n",
       "      <td>0.426124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>14.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>74.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>12500.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_since_last_donation  total_number_of_donations  \\\n",
       "count                  748.000000                 748.000000   \n",
       "mean                     9.506684                   5.514706   \n",
       "std                      8.095396                   5.839307   \n",
       "min                      0.000000                   1.000000   \n",
       "25%                      2.750000                   2.000000   \n",
       "50%                      7.000000                   4.000000   \n",
       "75%                     14.000000                   7.000000   \n",
       "max                     74.000000                  50.000000   \n",
       "\n",
       "       total_blood_donated  months_since_first_donation       class  \n",
       "count           748.000000                   748.000000  748.000000  \n",
       "mean           1378.676471                    34.282086    0.237968  \n",
       "std            1459.826781                    24.376714    0.426124  \n",
       "min             250.000000                     2.000000    0.000000  \n",
       "25%             500.000000                    16.000000    0.000000  \n",
       "50%            1000.000000                    28.000000    0.000000  \n",
       "75%            1750.000000                    50.000000    0.000000  \n",
       "max           12500.000000                    98.000000    1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bt_df = pd.read_csv(\"blood_transfusion.csv\")\n",
    "bt_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "months_since_last_donation_avg = np.zeros((75, 3))\n",
    "\n",
    "for i in range(len(months_since_last_donation_avg)):\n",
    "    months_since_last_donation_avg[i, 0] = i+1\n",
    "\n",
    "for index, row in bt_df.iterrows():\n",
    "    months_since_last_donation_avg[int(row[0]), 2] += 1\n",
    "    avg_class = (months_since_last_donation_avg[int(row[0]), 1] + row[4])/months_since_last_donation_avg[int(row[0]), 2]\n",
    "    months_since_last_donation_avg[int(row[0]), 1] = avg_class\n",
    "\n",
    "months_since_last_donation_fig = go.Figure()\n",
    "\n",
    "# Iterate over each row in the matrix and plot it\n",
    "months_since_last_donation_fig.add_trace(go.Scatter(\n",
    "    x=months_since_last_donation_avg[:, 0],  # Use the first column as x-values\n",
    "    y=months_since_last_donation_avg[:, 1],  # Use the second column as y-values\n",
    "    mode='lines+markers',  # Connect the points with lines\n",
    "    name='Data Points'\n",
    "))\n",
    "\n",
    "# Update layout for titles and labels\n",
    "months_since_last_donation_fig.update_layout(\n",
    "    title='Chances of coming back after last donation',\n",
    "    xaxis_title='Months passed since last donation',\n",
    "    yaxis_title='Chances of coming back',\n",
    "    xaxis=dict(range=[0, 30])\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "months_since_last_donation_fig.show()\n",
    "\n",
    "distribution_fig = go.Figure()\n",
    "\n",
    "for i in range(len(months_since_last_donation_avg)):\n",
    "    distribution_fig.add_trace(go.Bar(\n",
    "        x=months_since_last_donation_avg[:, 0],  # Use column names as x-coordinates\n",
    "        y=months_since_last_donation_avg[:, 2],  # Use row values as y-coordinates\n",
    "        marker = dict(color = 'red')\n",
    "    ))\n",
    "\n",
    "distribution_fig.update_layout(\n",
    "    xaxis=dict(range=[0, 30])\n",
    ")\n",
    "\n",
    "distribution_fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments_df= np.array_split(bt_df, 15)\n",
    "\n",
    "class_distribution_fig = go.Figure()\n",
    "avg_class = np.zeros((15, 2))\n",
    "\n",
    "for i in range(len(segments_df)):\n",
    "    avg_class[i][1] = sum(split_df[i]['class'])/len(segments_df[i])\n",
    "    avg_class[i][0] = i+1\n",
    "\n",
    "class_distribution_fig = go.Figure()\n",
    "\n",
    "class_distribution_fig.add_trace(go.Scatter(\n",
    "    x=avg_class[:, 0],  # Use the first column as x-values\n",
    "    y=avg_class[:, 1],  # Use the second column as y-values\n",
    "    mode='lines+markers',  # Connect the points with lines\n",
    "    name='Data Points'\n",
    "))\n",
    "\n",
    "class_distribution_fig.update_layout(\n",
    "    title='Distribution of class variable across data',\n",
    "    xaxis_title='Segments of Data',\n",
    "    yaxis_title='Average Value of Class',\n",
    ")\n",
    "\n",
    "class_distribution_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Creating a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_attribute = bt_df['class']\n",
    "variables = bt_df.drop(columns = [\"class\"])\n",
    "\n",
    "class_train8020, class_test8020, variables_train8020, variables_test8020= train_test_split(class_attribute, variables, test_size=0.2, train_size = 0.8)\n",
    "class_train9010, class_test9010, variables_train9010, variables_test9010= train_test_split(class_attribute, variables, test_size=0.1, train_size = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.1: Manual implementation of a KNN classifier algorithm\n",
    "\n",
    "def euclidean_distance(point1, point2):\n",
    "    distance = 0\n",
    "    for i in range(len(point1)):\n",
    "        distance += (point1[i] - point2[i]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "def get_neighbors(training_set, labels, test_instance, k):\n",
    "    distances = []\n",
    "    for index in range(len(training_set)):\n",
    "        dist = euclidean_distance(test_instance, training_set[index])\n",
    "        distances.append((labels[index], dist))\n",
    "    \n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    neighbors = distances[:k]\n",
    "    return [neighbor[0] for neighbor in neighbors]\n",
    "\n",
    "def predict_classification(training_set, labels, test_instance, k):\n",
    "    neighbors = get_neighbors(training_set, labels, test_instance, k)\n",
    "    count = Counter(neighbors) \n",
    "    prediction = count.most_common(1)[0][0]\n",
    "    return prediction\n",
    "\n",
    "def confusion_matrix(predicted, actual):\n",
    "    predicted = np.array(predicted)\n",
    "    actual = np.array(actual)\n",
    "\n",
    "    true_positive = np.sum((predicted == 1) & (actual == 1))\n",
    "    false_positive = np.sum((predicted == 1) & (actual == 0))\n",
    "\n",
    "    true_negative = np.sum((predicted == 0) & (actual == 0))\n",
    "    false_negative = np.sum((predicted == 1) & (actual == 0))\n",
    "\n",
    "    matrix_data = {'True positive': true_positive, 'False positive': false_positive, 'True negative': true_negative, 'False negative': false_negative}\n",
    "    confusion_table = pd.DataFrame(matrix_data, index=[0]) \n",
    "\n",
    "    return confusion_table\n",
    "\n",
    "def precision(predicted, actual):\n",
    "    \n",
    "    if (int(confusion_matrix(predicted,actual)['True positive']) + int(confusion_matrix(predicted,actual)['False positive'])) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    precision = int(confusion_matrix(predicted,actual)['True positive']) / int((confusion_matrix(predicted,actual)['True positive']) + int(confusion_matrix(predicted,actual)['False positive']))\n",
    "    return precision\n",
    "\n",
    "def recall(predicted, actual):\n",
    "    if (int(confusion_matrix(predicted,actual)['True positive']) + int(confusion_matrix(predicted,actual)['False negative'])) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    recall = int(confusion_matrix(predicted,actual)['True positive']) / (int(confusion_matrix(predicted,actual)['True positive']) + int(confusion_matrix(predicted,actual)['False negative']))\n",
    "    return recall\n",
    "\n",
    "knn8020_predicted = np.zeros(150)\n",
    "knn8020_correct= np.zeros(150)\n",
    "\n",
    "for i in range(len(knn8020_predicted)):\n",
    "    predicted_label = predict_classification(variables_train8020.to_numpy(), class_train8020.to_numpy(), variables_test8020.to_numpy()[i], 20)\n",
    "    knn8020_predicted[i] = predicted_label\n",
    "    knn8020_correct[i] = class_test8020.to_numpy()[i]\n",
    "    \n",
    "\n",
    "evaluater_data = {'Predicted Class': knn8020_predicted, 'Correct Class': knn8020_correct}\n",
    "knn8020_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(confusion_matrix(knn8020_evaluater['Predicted Class'], knn8020_evaluater['Correct Class']))\n",
    "\n",
    "print(f'For a KNN Classifier with a 80-20 split, the precision is: {precision(knn8020_evaluater['Predicted Class'], knn8020_evaluater['Correct Class'])*100}% and the recall is: {recall(knn8020_evaluater['Predicted Class'], knn8020_evaluater['Correct Class'])*100}%')\n",
    "\n",
    "knn9010_predicted = np.zeros(75)\n",
    "knn9010_correct= np.zeros(75)\n",
    "\n",
    "for i in range(len(knn9010_predicted)):\n",
    "    predicted_label = predict_classification(variables_train9010.to_numpy(), class_train9010.to_numpy(), variables_test9010.to_numpy()[i], 20)\n",
    "    knn9010_predicted[i] = predicted_label\n",
    "    knn9010_correct[i] = class_test9010.to_numpy()[i]\n",
    "    \n",
    "\n",
    "evaluater_data = {'Predicted Class': knn9010_predicted, 'Correct Class': knn9010_correct}\n",
    "knn9010_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a KNN Classifier with a 90-10 split, the precision is: {precision(knn9010_evaluater['Predicted Class'], knn9010_evaluater['Correct Class'])*100}% and the recall is: {recall(knn9010_evaluater['Predicted Class'], knn9010_evaluater['Correct Class'])*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.2: Naive Bayes Classifier\n",
    "\n",
    "nb8020_correct= np.zeros(150)\n",
    "\n",
    "nb_clf8020 = GaussianNB()\n",
    "nb_clf8020.fit(variables_train8020, class_train8020)\n",
    "\n",
    "for i in range(len(nb8020_correct)):\n",
    "    nb8020_correct[i] = class_test8020.to_numpy()[i]\n",
    "\n",
    "nb8020_predicted = nb_clf8020.predict(variables_test8020)\n",
    "\n",
    "evaluater_data = {'Predicted Class': nb8020_predicted, 'Correct Class': nb8020_correct}\n",
    "nb8020_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a Naive Bayes Classifier with a 80-20 split, the precision is: {int(precision(nb8020_evaluater['Predicted Class'],\n",
    "    nb8020_evaluater['Correct Class'])*100)}% and the recall is: {int(recall(nb8020_evaluater['Predicted Class'], nb8020_evaluater['Correct Class'])*100)}%')\n",
    "\n",
    "nb9010_correct= np.zeros(75)\n",
    "\n",
    "nb_clf9010 = GaussianNB()\n",
    "nb_clf9010.fit(variables_train9010, class_train9010)\n",
    "\n",
    "for i in range(len(nb9010_correct)):\n",
    "    nb9010_correct[i] = class_test9010.to_numpy()[i]\n",
    "\n",
    "nb9010_predicted = nb_clf9010.predict(variables_test9010)\n",
    "\n",
    "evaluater_data = {'Predicted Class': nb9010_predicted, 'Correct Class': nb9010_correct}\n",
    "nb9010_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a Naive Bayes Classifier with a 90-10 split, the precision is: {int(precision(nb9010_evaluater['Predicted Class'],\n",
    "    nb9010_evaluater['Correct Class'])*100)}% and the recall is: {int(recall(nb9010_evaluater['Predicted Class'], nb9010_evaluater['Correct Class'])*100)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.3 Support Vector Classifier\n",
    "\n",
    "svc8020_correct= np.zeros(150)\n",
    "\n",
    "svc_clf8020 = SVC(gamma='auto')\n",
    "svc_clf8020.fit(variables_train8020, class_train8020)\n",
    "\n",
    "for i in range(len(svc8020_correct)):\n",
    "    svc8020_correct[i] = class_test8020.to_numpy()[i]\n",
    "\n",
    "svc8020_predicted = svc_clf8020.predict(variables_test8020)\n",
    "\n",
    "evaluater_data = {'Predicted Class': svc8020_predicted, 'Correct Class': svc8020_correct}\n",
    "svc8020_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a Support Vector Classifier with a 80-20 split, the precision is: {int(precision(svc8020_evaluater['Predicted Class'],\n",
    "    svc8020_evaluater['Correct Class'])*100)}% and the recall is: {int(recall(svc8020_evaluater['Predicted Class'], svc8020_evaluater['Correct Class'])*100)}%')\n",
    "\n",
    "svc9010_correct= np.zeros(75)\n",
    "\n",
    "svc_clf9010 = SVC(gamma='auto')\n",
    "svc_clf9010.fit(variables_train9010, class_train9010)\n",
    "\n",
    "for i in range(len(svc9010_correct)):\n",
    "    svc9010_correct[i] = class_test9010.to_numpy()[i]\n",
    "\n",
    "svc9010_predicted = svc_clf9010.predict(variables_test9010)\n",
    "\n",
    "evaluater_data = {'Predicted Class': svc9010_predicted, 'Correct Class': svc9010_correct}\n",
    "svc9010_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a Support Vector Classifier with a 90-10 split, the precision is: {int(precision(svc9010_evaluater['Predicted Class'],\n",
    "    svc9010_evaluater['Correct Class'])*100)}% and the recall is: {int(recall(svc9010_evaluater['Predicted Class'], svc9010_evaluater['Correct Class'])*100)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4.4 Multilayer Percetron (Neural Network) Classifier\n",
    "\n",
    "mlp8020_correct= np.zeros(150)\n",
    "\n",
    "mlp_clf8020 = MLPClassifier(max_iter=300)\n",
    "mlp_clf8020.fit(variables_train8020, class_train8020)\n",
    "\n",
    "for i in range(len(mlp8020_correct)):\n",
    "    mlp8020_correct[i] = class_test8020.to_numpy()[i]\n",
    "\n",
    "mlp8020_predicted = mlp_clf8020.predict(variables_test8020)\n",
    "\n",
    "evaluater_data = {'Predicted Class': mlp8020_predicted, 'Correct Class': mlp8020_correct}\n",
    "mlp8020_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a Multilayer Perceptron Classifier with a 80-20 split, the precision is: {int(precision(mlp8020_evaluater['Predicted Class'],\n",
    "    mlp8020_evaluater['Correct Class'])*100)}% and the recall is: {int(recall(mlp8020_evaluater['Predicted Class'], mlp8020_evaluater['Correct Class'])*100)}%')\n",
    "\n",
    "mlp9010_correct= np.zeros(75)\n",
    "\n",
    "mlp_clf9010 = MLPClassifier(max_iter=300)\n",
    "mlp_clf9010.fit(variables_train9010, class_train9010)\n",
    "\n",
    "for i in range(len(mlp9010_correct)):\n",
    "    mlp9010_correct[i] = class_test9010.to_numpy()[i]\n",
    "\n",
    "mlp9010_predicted = mlp_clf9010.predict(variables_test9010)\n",
    "\n",
    "evaluater_data = {'Predicted Class': mlp9010_predicted, 'Correct Class': mlp9010_correct}\n",
    "mlp9010_evaluater = pd.DataFrame(evaluater_data)\n",
    "\n",
    "print(f'For a Multilayer Perceptron Classifier with a 90-10 split, the precision is: {int(precision(mlp9010_evaluater['Predicted Class'],\n",
    "    mlp9010_evaluater['Correct Class'])*100)}% and the recall is: {int(recall(mlp9010_evaluater['Predicted Class'], mlp9010_evaluater['Correct Class'])*100)}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Evaluation of classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.1 Manual implementation of confusion matrix\n",
    "\n",
    "#It was implemented in 4.1, under function confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.2 Classification Report\n",
    "\n",
    "print(\"Classification Report of Naive Bayes Classifier with 80-20 split:\\n\", classification_report(nb8020_correct, nb8020_predicted))\n",
    "print(\"Classification Report of Naive Bayes Classifier with 90-10 split:\\n\", classification_report(nb9010_correct, nb9010_predicted, zero_division = 0))\n",
    "print(\"Classification Report of KNN Classifier with 80-20 split:\\n\", classification_report(knn8020_correct, knn8020_predicted))\n",
    "print(\"Classification Report of KNN Classifier with 90-10 split:\\n\", classification_report(knn9010_correct, knn9010_predicted, zero_division = 0))\n",
    "print(\"Classification Report of Support Vector Classifier with 80-20 split:\\n\", classification_report(svc8020_correct, svc8020_predicted))\n",
    "print(\"Classification Report of Support Vector Classifier with 90-10 split:\\n\", classification_report(svc9010_correct, svc9010_predicted, zero_division = 0))\n",
    "print(\"Classification Report of Multilayer Perceptron Classifier with 80-20 split:\\n\", classification_report(mlp8020_correct, mlp8020_predicted))\n",
    "print(\"Classification Report of Multilayer Perceptron Classifier with 90-10 split:\\n\", classification_report(mlp9010_correct, mlp9010_predicted, zero_division = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.3 Fbeta Score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
